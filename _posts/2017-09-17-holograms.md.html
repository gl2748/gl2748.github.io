**Computational Scratch Holograms**
  **Iain Maitland**
    Experimenting with 3D point clouds encoded in 2D vector graphics and machined onto reflective surfaces.

![Figure [model]: A 3D computer model]({{ site.url }}/assets/Bluetooth_rendered.png width="480px")

![Figure [initial]: Points to describe a 3D model]({{ site.url }}/assets/Bluetooth_wireframe.png width="480px")

![Figure [svg]: Calculated highlight paths]({{ site.url }}/assets/Bluetooth_paths.png width="480px")

![Figure [toolpath]: CNC Toolpath]({{ site.url }}/assets/Bluetooth_toolpath.png width="480px")

# Video Demo
![Figure [hologram]: Engraving on 12cm x 12cm copper plate]({{ site.url }}/assets/holo.mp4)

# Abstract
Presented here is a method for computational scratch holography also known as 'highlight holography' or 'abrasion holography' .

This method converts three-dimensional computer models into two-dimensional vectors representing mechanical 'holograms' that are then machined onto a reflective surfaces.

The surface consists of small grooves or 'scratches' each of which produces a highlight when illuminated by a directional light.
This highlight appears in different places for different view positions. 
Grooves with a particular path, can lend  the changing position of the highlight the correct binocular and motion parallax corresponding to a virtual 3D point position.

The pipeline presented here begins with a 3D computer model and a desired view position fig. [model].
We then sample the model to generate points that depict its features accurately fig. [initial].
For each of these representative points we compute a location on the reflective surface that corresponds to the location of the desired highlight for that point and that view position.
We then move the view position, and repeat the computation to determine the highlight location again.

Each point in our cloud therefore has a corresponding highlight location on the reflective surface for each desired viewing position. 

We then draw a bezier curve that passes through each of these highlight locations, in this way smoothing the individual point's highlight location between view positions fig. [svg].

Finally we machine these paths fig. [toolpath] as grooves onto a surface - using a diamond-tipped engraving bit to trace the paths over the surface of a reflective material fig. [hologram].

This method offers some important advantages and adds to the work described in the related work section.

  1. It is relatively trivial to use raycasting to determine if a point should not be visible for a given view position. This gives our holographic image opaque characteristics.
  2. As easily as we can smooth between changing viewing positions we can smooth between changing point positions. We can have animated holograms that change their shape and features as the viewing position changes.
  3. The vector graphics generated by this method are accessible to a wide range of potential users and existing CNC manufacturing processes. 

## Related Work

Abrasion holograms have been popular projects amongst hobbyists for some time.
William J Beaty described much of what is possible with this technique in 1995 - http://amasci.com/amateur/holo1.html

While this project from  2008 demonstrates software made by Mike Miller a student at the time at Milwaukee School of Engineering.
https://www.youtube.com/watch?v=JaGZ651U4j4

Similarly, Matthew Brand a researcher and artist has evidently developed advanced proprietary software and manufacturing processes for this type of Hologram as well as indicating further work (litho, etc...)
http://www.zintaglio.com/

Generally  there have been incremental developments in the process and novel applications for the effect.
For example artist Tristam Duke http://www.infinitylightscience.com/ added an abrasion hologram to Jack White's album 'Lanzarotto' https://www.youtube.com/watch?v=YGH2m5sRylM

And in 2016 Disney researchers patented a method for computational generated abrasion holograms. https://www.google.com/patents/US20120019882

# Setup

******************************************************************
*                                                                *
*                                                                *
*                                                                *
*                                                                *
*                                                                *
*                                                      \         *
*                                                  o v (+ eye    *
*                                                 /    /         *
*                                                /               *
*                                  c+-------+   /                *
*                                  /|      /|  /                 *
*                                 +-------+ | /                  *
*                                 | |     | |/                   *
*                                 | +-----| /                    *
*                                 |/      |/                     *
*                      lo         +-------o                      *
*                        \               / p                     *
*                         \             /                        *
*                          \           /                         *
*                           \         /                          *
*                            \       /                           *
*                             \     /                            *
*                       +------\---/------+                      *
*                      /        v /        \                     *
*                 y           ---*--- q     \                    *
*                 ^  ^x           i          \                   *
*                 | /                         \                  *
*                 |/                           \                 *
*                 +---> z ----------------------+                *
*                                                r               *
*                                                                *
*                                                                *
******************************************************************
[Figure [setup]: Setup for derivation of the reflective point corresponding to one virtual point __p__. The viewer position is centered at __v__, and parallel light rays are incident in direction __l__.]

Considering a single groove __q__ on the hologram surface, which focuses directional incident light to produce an image at the 3D point __p__ when viewer is at __v__.

As shown in fig. [setup] the center of the groove __i__ is found by casting a ray from the central view position __v__ through the sample point __p__ and intersecting it with the hologram plane __r__.

$$ i = v - \left(\frac{v_y}{p_y - v_y}\right)(p-v) $$

Zooming in on the groove [Figure [groove]], we see how the incident light interacts with the interior of the groove, passing through the virtual point __p__ and onto the viewer at __v__. 

******************************************************************
*                                                                *
*                                                                *
*                             l|             \                   *
*                              v         o v (+ eye              *
*                              |        /    /                   *
*                              |       /                         *
*                 y            |      /                          *
*                 ^  ^x        |     o                           *
*                 | /          |    / p                          *
*                 |/           |   /                             *
*                 +---> z --+  |  /   +----------                *
*                            \ | /   /           r               *
*                             \|/   /                            *
*                              +   /                             *
*                               \ /                              *
*                                *                               *
*                                 i                              *
*                                                                *
******************************************************************
[Figure [groove]: Detailed view of the cross-sectional profile of a groove for one point]

The length of the groove __q__ as well as its shape is determined by the change in viewer position.
Moving the viewer position __v__ gives another point of intersection on the plane. Joining these two points of intersection gives us a smoothed path.

Because we do not have total control over the groove's cross-sectional profile beyond the tooling we confine viewer movement to a circular orbit.
This generates circular grooves that create the desired motion parallax for a rotating hologram plane __r__, or an orbiting viewing position.

As a certain point is occluded by some other point or surface in the virtual scene we interupt the continuous path and resume it when the point comes back into view.
This lends our hologram surface opaque characteristics. 

To optimise  the initial setup  we take into account a few things.

1. The interior shape of the groove surface created by the available tools. For example using a 120-degree diamond tip: We setup the desired view position to fall within the path of light reflected from inside the groove cut by the available tool.

2. Considering the distribution of representative points And final-scale of the hologram we both randomly distribute particles over the object surface and add a particle at each vertex.
For smaller scale holograms adding points at vertices naturally builds a representative point cloud. 

# Code

## Pseudo Code

First we manually generate a point cloud __c__ that represents the surface details of some 3d object. We do this using Blender's particle system.
We generate two particle systems. One that attaches particles to the vertices of our object, another that makes a random and even distribution of particles over the faces of our object.
Combined this creates a satisfactory cloud representation of the object.

Add a plane __r__ to represent the reflective surface we will be engraving the hologram onto.

Add an viewer position __v__ , which is used to calculate, for each point __p__ in the point cloud __c__ :
 - When the point __p__ is occluded by opaque elements in the scene, for example an opaque face of the object.
 - The point of intersection __i__ of a line that passes through the viewer position __v__ , the visible point __p__ and the plane __r__.

Having calculated the point of intersection for all the visible points __p__ we move the viewer position __v__.
 
Move the viewer position __v__  and recalculate this points of intersection __i__ on the plane.

Next we draw a continuous line __q__  through all of the intersection points for each highlight point to reflect the highlight point's movement over time. 
For each unique point in the point cloud we draw a distinct curve or set of curves (as the case may be when a point is occluded and subsequently reappears)

Having generated an individual path __q__ for each point __p__ as it remains visible through whatever motion cast these to an svg file.

## Github

Code is available as a Blender script on [github](https://github.com/gl2748/scratch-holograms)

We leverage a few useful tools from Blender's Python API and developer ecosystem, most crucially.

1. BVH trees, required for efficient raycasting.
2. Raycasting, required to determine if a point is visible.
3. Itertools, required to sort through the points of intersection, group them by consecutive view positions and virtual point they represent.
4. An SVG generator plugin for Blender, required to easily export the generated paths into toolpath software.

# Manufacturing

Having exported the lines drawn with this script in Blender as an SVG the SVG is imported into a tool-path generating software that outputs G-Code.

I have been using VCarve, thereafter it can be machined using a CNC equipped with Mach3 or similar.

Initially I got a trial membership at Techshop and a Tormach Personal CNC 1100 Mill was used, with a Tormach the bed size was limited however.
Thereafter I have been using a CNC router bed equipped with the diamond drag engraving bit from [Tormach](https://www.tormach.com/store/index.php?app=ecom&ns=prodshow&ref=32447). 

# Future work

The work documented here is still in progress. 

I am exploring a few interesting areas using this method, in particular animated holograms, temporary holograms and holograms at a large scale.

By the same token there are a number of areas where this process can be improved.
Notably optimizing the distribution of points across the 3D model surface.
Taking greater control of the groove interior and broadening the range of viewable positions.


<!-- Markdeep: --><style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src="markdeep.min.js"></script><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
